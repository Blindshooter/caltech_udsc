{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Remove all previous preparation data\n",
    "#!rm -rf prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import skimage \n",
    "from scipy import ndimage, misc\n",
    "\n",
    "\n",
    "resize = (64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "data = load_files('train')\n",
    "file_names = np.array(data['filenames'])\n",
    "target = np.array(data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22101"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading files from 240.watch-101...\n",
      "reading files from 230.trilobite-101...\n",
      "reading files from 110.hourglass...\n",
      "reading files from 160.pez-dispenser...\n",
      "reading files from 140.menorah-101...\n",
      "reading files from 020.brain-101...\n",
      "reading files from 180.screwdriver...\n",
      "reading files from 190.snake...\n",
      "reading files from 250.zebra...\n",
      "reading files from 150.octopus...\n",
      "reading files from 030.canoe...\n",
      "reading files from 200.stained-glass...\n",
      "reading files from 080.frog...\n",
      "reading files from 100.hawksbill-101...\n",
      "reading files from 010.beer-mug...\n",
      "reading files from 050.covered-wagon...\n",
      "reading files from 090.gorilla...\n",
      "reading files from 120.joy-stick...\n",
      "reading files from 220.toaster...\n",
      "reading files from 060.duck...\n",
      "reading files from 070.fire-extinguisher...\n",
      "reading files from 210.syringe...\n",
      "reading files from 130.license-plate...\n",
      "reading files from 040.cockroach...\n",
      "reading files from 170.rainbow...\n",
      "CPU times: user 47.2 s, sys: 368 ms, total: 47.6 s\n",
      "Wall time: 47.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_metadata = []\n",
    "\n",
    "for root, dirs, files in os.walk(\"./train\"):\n",
    "    for sf in dirs:\n",
    "        if sf.split('.')[0][-1]=='0':\n",
    "            print('reading files from {}...'.format(sf))\n",
    "        for f_name in os.listdir(os.path.join(\"./train\", sf)):\n",
    "            if not f_name.startswith('.'):\n",
    "                temp = misc.imread(os.path.join(\"./train\", sf, f_name)) # read image\n",
    "                # collect image metadata\n",
    "                image_metadata = []\n",
    "                image_metadata.extend([sf, f_name, os.path.join(\"./train\", sf, f_name)])\n",
    "                image_metadata.extend( list(temp.shape) if len(temp.shape) == 3\\\n",
    "                                      else [temp.shape[0], temp.shape[1], 1])\n",
    "                image_metadata.extend([temp.nbytes, temp.dtype])\n",
    "                # append image metadata to list\n",
    "                train_metadata.append(image_metadata)\n",
    "                \n",
    "train_metadata = pd.DataFrame(train_metadata)\n",
    "#train_metadata.head()\n",
    "train_metadata.columns = ['category','img_name', 'full_path', 'height','width','channels','byte_size','bit_depth']\n",
    "# select integer target (1-257)\n",
    "train_metadata['target'] = train_metadata['category'].str.split('.').apply(lambda x: int(x[0]))\n",
    "# image extension\n",
    "train_metadata['img_extension'] = train_metadata['img_name'].str.split('.').apply(lambda x: x[1])\n",
    "# just name without category indexes\n",
    "train_metadata['category_name'] = train_metadata['category'].str.split('.').apply(lambda x: x[1]).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "223.top-hat                50\n",
       "086.golden-gate-bridge     50\n",
       "179.scorpion-101           50\n",
       "099.harpsichord            50\n",
       "204.sunflower-101          50\n",
       "186.skunk                  51\n",
       "218.tennis-racket          51\n",
       "082.galaxy                 51\n",
       "201.starfish-101           51\n",
       "121.kangaroo-101           52\n",
       "053.desk-globe             52\n",
       "144.minotaur               52\n",
       "146.mountain-bike          52\n",
       "020.brain-101              53\n",
       "175.roulette-wheel         53\n",
       "059.drinking-straw         53\n",
       "062.eiffel-tower           53\n",
       "160.pez-dispenser          53\n",
       "066.ewer-101               53\n",
       "067.eyeglasses             53\n",
       "075.floppy-disk            53\n",
       "184.sheet-music            54\n",
       "084.giraffe                54\n",
       "248.yarmulke               54\n",
       "076.football-helmet        54\n",
       "215.telephone-box          54\n",
       "070.fire-extinguisher      54\n",
       "174.rotary-phone           54\n",
       "219.theodolite             54\n",
       "239.washing-machine        54\n",
       "                         ... \n",
       "101.head-phones           108\n",
       "214.teepee                109\n",
       "168.raccoon               110\n",
       "021.breadmaker            112\n",
       "227.treadmill             117\n",
       "005.baseball-glove        118\n",
       "158.penguin               119\n",
       "003.backpack              121\n",
       "137.mars                  126\n",
       "109.hot-tub               126\n",
       "148.mussels               144\n",
       "193.soccer-ball           144\n",
       "132.light-house           160\n",
       "129.leopards-101          160\n",
       "138.mattress              162\n",
       "240.watch-101             171\n",
       "092.grapes                171\n",
       "147.mushroom              172\n",
       "159.people                179\n",
       "090.gorilla               182\n",
       "012.binoculars            186\n",
       "008.bathtub               202\n",
       "126.ladder                212\n",
       "105.horse                 240\n",
       "011.billiards             248\n",
       "096.hammock               255\n",
       "232.t-shirt               328\n",
       "253.faces-easy-101        405\n",
       "145.motorbikes-101        768\n",
       "251.airplanes-101         770\n",
       "Length: 256, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metadata.groupby('category').size().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_preproc_save(path_to_file, path_to_save, resize_dim = (224,224)):\n",
    "    image = misc.imread(path_to_file)\n",
    "    if len(image.shape) == 2:\n",
    "        image = np.stack((image,)*3)\n",
    "    misc.imsave(path_to_save,misc.imresize(image, size=resize_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def val_split(files, target, uniform = 0, test_size = 0.3):\n",
    "    if uniform == 0:\n",
    "        X_train, X_val, y_train, y_val = train_test_split(files, target, test_size=0.30, random_state=242, stratify = target)\n",
    "    else:\n",
    "        X_train = []\n",
    "        X_val = []\n",
    "        for tg in list(set(target)):\n",
    "            list_to_split = files[target == tg]\n",
    "            #print (\"BBB\", list_to_split)\n",
    "            val = np.random.choice(list_to_split, uniform, replace=False)\n",
    "            #print(\"AAA\", val)\n",
    "            X_train += list(set(list_to_split)-set(val))\n",
    "            #print(\"CCC\", X_train)\n",
    "            X_val.extend(val)\n",
    "    \n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preproc_all(files, folder_to_save, resize = (224, 224)):\n",
    "    for f_name in files:\n",
    "        load_path = f_name\n",
    "        \n",
    "        sf_file = f_name.split('/')\n",
    "        \n",
    "        save_path = os.path.join(folder_to_save, sf_file[1], sf_file[2])\n",
    " \n",
    "        if not os.path.exists(os.path.join(folder_to_save, sf_file[1])):\n",
    "                os.makedirs(os.path.join(folder_to_save, sf_file[1]))\n",
    "        try:\n",
    "            image_preproc_save(load_path, save_path, resize)\n",
    "        except:\n",
    "            print(\"Failed_preprocessing for: {}\".format(load_path))\n",
    "        #print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = val_split(file_names, target, uniform = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18773\n",
      "3328\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!rm -rf prep224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed_preprocessing for: train/056.dog/.DS_Store\n",
      "CPU times: user 1min, sys: 776 ms, total: 1min 1s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preproc_all(X_train, os.path.join('prep13', 'train'), resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.7 s, sys: 124 ms, total: 17.8 s\n",
      "Wall time: 17.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preproc_all(X_val, os.path.join('prep13', 'val'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.4 s, sys: 300 ms, total: 26.7 s\n",
      "Wall time: 26.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "os.makedirs('prep13/test')\n",
    "for f_name in os.listdir('test'):\n",
    "    if not f_name.startswith('.'):\n",
    "        load_path = os.path.join('test', f_name)\n",
    "        save_path = os.path.join('prep13', 'test', f_name)\n",
    "        #try:\n",
    "        image_preproc_save(load_path, save_path, resize)\n",
    "        #except:\n",
    "            #print(\"Failed_preprocessing for: {}\".format(load_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
